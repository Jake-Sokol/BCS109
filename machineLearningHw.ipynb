{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machineLearningHw.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKAK67T9l4js"
      },
      "source": [
        "#1) Explain in words what accuracy, precision, and recall are.  Describe a situation when you would prefer one to another and where the shortcomings to each lays\n",
        "\n",
        "Accuracy - the measure of how correct a model's predictions were (correct predictions over total predictions).  Useful in a dataset that is balanced.  In a situation where you would want as many correct predictions (both true and false) without caring about how many incorrect predictions you made, accuracy would be important.\n",
        "\n",
        "Precision - a measure for the correctness of a positive prediction, or how often a positive prediction turns out to actually be positive.  For example, pregnancy tests need to have high precision - it is more important that the test's positive readings are true positives, and not as important if there are false negatives.\n",
        "\n",
        "Recall - the measure of how many true positives were predicted out of all of the positives in the set.  In a situation where you want to find as many true positives without caring about how nany false positives you also find, recall would be the most important metric.  For example, instead of finding all of the people who are at the highest risk of dying from the flu, a healthcare plan will just offer a flu shot to everyone, since the cost to produce is low and it is more important to get as many true positives as possible, without caring about how many false positives you get along the way.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Wp-PozmB0t"
      },
      "source": [
        "#2) What is a confusion matrix?\n",
        "\n",
        "A confusion matrix plots the amount of correct predictions (true positive, true negative) against the amount of incorrect predictions (false positive, false negative)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmnFwXkrmEXC"
      },
      "source": [
        "#3) Write the python code for accuracy, precision, recall, and F1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HaqBZ0Mq4pH"
      },
      "source": [
        "correct = truePositive + trueNegative\n",
        "total = truePositive + trueNegative + falsePositive + falseNegative\n",
        "\n",
        "accuracy = correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNX4XBaTq8QI"
      },
      "source": [
        "precision = truePositive / (truePositive + falsePositive)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KptyMaHV6xnf"
      },
      "source": [
        "recall = truePositive / (truePositive + falseNegative)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEnKUkAT7D_k"
      },
      "source": [
        "precision = truePositive / (truePositive + falsePositive)\n",
        "recall = truePositive / (truePositive + falseNegative)\n",
        "\n",
        "f1Score = 2 * precision * recall / (precision + recall)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnuQn6iE8ADX"
      },
      "source": [
        "#4) Give your own example of a type 1 and type 2 error\n",
        "\n",
        "A type 1 error would be when a test for a virus or disease comes back positive but the person isn't actually sick.\n",
        "\n",
        "A type 2 error would be when a test for a virus or disease comes back negative but the person is actually sick."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2scDDVR8E55"
      },
      "source": [
        "#5) Why do we use train_test_split() function from Python when analyzing data? What is the point of splitting data?\n",
        "\n",
        "this function is used to split your data into two subsets, one to train the data and one to test it.  Splitting the data is useful because if you use the same data set for both training and testing, you may increase the chances of making inaccurate predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zdPDCg3ICmD"
      },
      "source": [
        "#6) What is the bias vs. variance tradeoff?\n",
        "\n",
        "bias - the difference between the average prediction of a model and the correct value it is trying to predict.  Models with high bias spend less time training data, leading to a large amount of errors on training and testing data.\n",
        "\n",
        "variance - refers to an algorithms sensitivity to specific sets of training data.  Models with high variance spend a lot of time training data,  These models perform well on training data but have high error rates on testing data.\n",
        "\n",
        "The bias-variance tradeoff is the effort to find a good balance between bias and variance in your model, so as not to over or underfit the data.\n",
        "\n"
      ]
    }
  ]
}